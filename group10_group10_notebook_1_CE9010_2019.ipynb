{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Prediction\n",
    "\n",
    "### Project Description\n",
    "This project was aimed at gaining an understanding to see if we are able to train different models to predict stock market prices, finding the best opportunities to buy and sell them to maximise our profits. We have attempted to optimise 4 different prediction models, with the code of the entire project split across 5 notebooks. After which, we compared the prediction models based on their ability to predict by the RMSE (root mean square error) and MAPE (mean absolute percentage error) of the test set.\n",
    "\n",
    "####  Models Optimised\n",
    "* Moving Average\n",
    "* Linear Regression\n",
    "* XG Boost\n",
    "* LSTM (RNN)\n",
    "\n",
    "####  About the Notebooks\n",
    "This first notebook was used for webscraping of Yahoo Finances' data on Raffles Medical Group Ltd's stock history from year 2015. The subsequent 4 notebooks were done individually by the 3 of us. We have sorted, processed and split the data indivdiually in our own prediction models. Thengxuan optimised Linear Regression and Moving Average, Ziyang optimised XGBoost and Amanda optimised LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless') \n",
    "chrome_options.add_argument(\"--start-maximized\");\n",
    "browser = webdriver.Chrome(executable_path='chromedriver',options=chrome_options)\n",
    "browser.get('https://sg.finance.yahoo.com/quote/BSL.SI/history?period1=1427241600&period2=1585094400&interval=1d&filter=history&frequency=1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (100):\n",
    "    browser.execute_script(\"window.scrollTo(0, 1000*document.body.scrollHeight);\")#Scroll 100 times downwards using webdri\n",
    "    \n",
    "soup = BeautifulSoup(browser.page_source, 'html.parser')   \n",
    "search = soup.find(id='site-content')\n",
    "table = soup.find_all(class_='Pb(10px) Ovx(a) W(100%)')\n",
    "indivlisting = soup.find_all(class_='BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)')\n",
    "\n",
    "whole_list = []\n",
    "counter =0\n",
    "for i in soup.find_all(class_='BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)'):\n",
    "    glist = []\n",
    "    for g in i.find_all('td'):\n",
    "        for h in g.find_all('span'):\n",
    "            hh = h.get_text()\n",
    "            glist.append(hh)\n",
    "    print(len(glist))\n",
    "    if len(glist) == 7: #because 7 features\n",
    "        whole_list.append(glist)\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "print(whole_list)\n",
    "listing_stuff = pd.DataFrame(whole_list, columns =['Date','Open','High','Low','Close','AdjClose','Vol'])\n",
    "print(listing_stuff)\n",
    "\n",
    "listing_stuff.to_csv('Yahoo.csv')\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
